{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow with H2O \n",
    "\n",
    "This notebook shows how to use the tensorflow backend to tackle a simple image classification problem.\n",
    "\n",
    "We start by connecting to our h2o cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>40 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>fmilo</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>12.48 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>40</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>40</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         40 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    1 day\n",
       "H2O cluster name:           fmilo\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    12.48 Gb\n",
       "H2O cluster total cores:    40\n",
       "H2O cluster allowed cores:  40\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(port=54321, nthreads=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make sure that the H2O cluster has the DeepWater distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some python utilities library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we configure the IPython notebook to have nice visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the path to your h2o installation\n",
    "and download the 'bigdata' dataset using `./gradlew syncBigdataLaptop` from the H2O source distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H2O_PATH=os.path.expanduser(\"~/h2o-3/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Task\n",
    "\n",
    "H2O DeepWater allows you to specify a list of URIs (file paths) or URLs (links) to images, together with a response column (either a class membership (enum) or regression target (numeric)).\n",
    "\n",
    "For this example, we use a small dataset that has a few hundred images, and three classes: cat, dog and mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "[267, 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1                                                             </th><th>C2  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/102194502_49f003abd9.jpg </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/11146807_00a5f35255.jpg  </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/1140846215_70e326f868.jpg</td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/114170569_6cbdf4bbdb.jpg </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/1217664848_de4c7fc296.jpg</td><td>cat </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frame = h2o.import_file(H2O_PATH + \"/bigdata/laptop/deepwater/imagenet/cat_dog_mouse.csv\")\n",
    "print(frame.dim)\n",
    "print(frame.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a LeNet image classification model in H2O, simply specify `network = \"lenet\"` and the **Tensorflow** backend to use the tensorflow lenet implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1479433139451_1\n",
      "Status of Deep Learning Model: lenet, 4.9 MB, predicting C2, 3-class classification, 134,144 training samples, mini-batch size 32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2352</td>\n",
       "<td>0.0044086</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate        momentum\n",
       "--  ---------------  ----------  ----------\n",
       "    2352             0.00440861  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.243990757963\n",
      "RMSE: 0.493954206342\n",
      "LogLoss: 0.877531867391\n",
      "Mean Per-Class Error: 0.315439992422\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>cat</b></td>\n",
       "<td><b>dog</b></td>\n",
       "<td><b>mouse</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>74.0</td>\n",
       "<td>3.0</td>\n",
       "<td>13.0</td>\n",
       "<td>0.1777778</td>\n",
       "<td>16 / 90</td></tr>\n",
       "<tr><td>29.0</td>\n",
       "<td>40.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.5294118</td>\n",
       "<td>45 / 85</td></tr>\n",
       "<tr><td>20.0</td>\n",
       "<td>2.0</td>\n",
       "<td>70.0</td>\n",
       "<td>0.2391304</td>\n",
       "<td>22 / 92</td></tr>\n",
       "<tr><td>123.0</td>\n",
       "<td>45.0</td>\n",
       "<td>99.0</td>\n",
       "<td>0.3108614</td>\n",
       "<td>83 / 267</td></tr></table></div>"
      ],
      "text/plain": [
       "cat    dog    mouse    Error     Rate\n",
       "-----  -----  -------  --------  --------\n",
       "74     3      13       0.177778  16 / 90\n",
       "29     40     16       0.529412  45 / 85\n",
       "20     2      70       0.23913   22 / 92\n",
       "123    45     99       0.310861  83 / 267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6891386</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8876405</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.689139\n",
       "2    0.887641\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:40:51</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:40:54</td>\n",
       "<td> 4.655 sec</td>\n",
       "<td>419 obs/sec</td>\n",
       "<td>3.8352060</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.8095751</td>\n",
       "<td>7.6691595</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:40:59</td>\n",
       "<td> 9.717 sec</td>\n",
       "<td>3967 obs/sec</td>\n",
       "<td>111.2209738</td>\n",
       "<td>29</td>\n",
       "<td>29696.0</td>\n",
       "<td>0.8095645</td>\n",
       "<td>7.0473993</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:41:04</td>\n",
       "<td>14.750 sec</td>\n",
       "<td>4671 obs/sec</td>\n",
       "<td>218.6067416</td>\n",
       "<td>57</td>\n",
       "<td>58368.0</td>\n",
       "<td>0.6207586</td>\n",
       "<td>1.0507603</td>\n",
       "<td>0.5093633</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:41:09</td>\n",
       "<td>19.802 sec</td>\n",
       "<td>4965 obs/sec</td>\n",
       "<td>325.9925094</td>\n",
       "<td>85</td>\n",
       "<td>87040.0</td>\n",
       "<td>0.4939542</td>\n",
       "<td>0.8775319</td>\n",
       "<td>0.3108614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:41:14</td>\n",
       "<td>24.965 sec</td>\n",
       "<td>5194 obs/sec</td>\n",
       "<td>441.0486891</td>\n",
       "<td>115</td>\n",
       "<td>117760.0</td>\n",
       "<td>0.8256194</td>\n",
       "<td>12.4554604</td>\n",
       "<td>0.6816479</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:41:17</td>\n",
       "<td>27.778 sec</td>\n",
       "<td>5267 obs/sec</td>\n",
       "<td>502.4119850</td>\n",
       "<td>131</td>\n",
       "<td>134144.0</td>\n",
       "<td>0.8256193</td>\n",
       "<td>12.4109633</td>\n",
       "<td>0.6816479</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:41:17</td>\n",
       "<td>27.979 sec</td>\n",
       "<td>5252 obs/sec</td>\n",
       "<td>502.4119850</td>\n",
       "<td>131</td>\n",
       "<td>134144.0</td>\n",
       "<td>0.4939542</td>\n",
       "<td>0.8775319</td>\n",
       "<td>0.3108614</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-11-17 17:40:51  0.000 sec                     0         0             0          nan              nan                 nan\n",
       "    2016-11-17 17:40:54  4.655 sec   419 obs/sec       3.83521   1             1024       0.809575         7.66916             0.655431\n",
       "    2016-11-17 17:40:59  9.717 sec   3967 obs/sec      111.221   29            29696      0.809565         7.0474              0.655431\n",
       "    2016-11-17 17:41:04  14.750 sec  4671 obs/sec      218.607   57            58368      0.620759         1.05076             0.509363\n",
       "    2016-11-17 17:41:09  19.802 sec  4965 obs/sec      325.993   85            87040      0.493954         0.877532            0.310861\n",
       "    2016-11-17 17:41:14  24.965 sec  5194 obs/sec      441.049   115           117760     0.825619         12.4555             0.681648\n",
       "    2016-11-17 17:41:17  27.778 sec  5267 obs/sec      502.412   131           134144     0.825619         12.411              0.681648\n",
       "    2016-11-17 17:41:17  27.979 sec  5252 obs/sec      502.412   131           134144     0.493954         0.877532            0.310861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = H2ODeepWaterEstimator(epochs=500, network = \"lenet\", backend=\"tensorflow\")\n",
    "model.train(x=[0],y=1, training_frame=frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to build your own Tensorflow network architecture, then this is easy as well.\n",
    "In this example script, we are using the **Tensorflow** backend. \n",
    "Models can easily be imported/exported between H2O and Tensorflow since H2O uses Tensorflow's format for model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_model(w, h, channels, classes):\n",
    "    import json\n",
    "    import tensorflow as tf    \n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        size = w * h * channels\n",
    "        x = tf.placeholder(tf.float32, [None, size])\n",
    "        W = tf.Variable(tf.zeros([size, classes]))\n",
    "        b = tf.Variable(tf.zeros([classes]))\n",
    "        y = tf.matmul(x, W) + b\n",
    "\n",
    "        # labels\n",
    "        y_ = tf.placeholder(tf.float32, [None, classes])\n",
    "     \n",
    "        # accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1),                                                                                                                                                                                                                                   \n",
    "                                       tf.argmax(y_, 1))                       \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        # train\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "        tf.add_to_collection(\"train\", train_step)\n",
    "        # this is required by the h2o tensorflow backend\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        \n",
    "        init = tf.initialize_all_variables()\n",
    "        tf.add_to_collection(\"init\", init)\n",
    "        tf.add_to_collection(\"logits\", y)\n",
    "        saver = tf.train.Saver()\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": x.name, \"categorical_labels\": y_.name}, \n",
    "                \"outputs\": {\"categorical_logits\": y.name}, \n",
    "                \"metrics\": {\"accuracy\": accuracy.name, \"total_loss\": cross_entropy.name},\n",
    "                \"parameters\": {\"global_step\": global_step.name},\n",
    "        })\n",
    "        print(meta)\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "        filename = \"/tmp/lenet_tensorflow.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"metrics\": {\"total_loss\": \"Mean_1:0\", \"accuracy\": \"Mean:0\"}, \"inputs\": {\"categorical_labels\": \"Placeholder_1:0\", \"batch_image_input\": \"Placeholder:0\"}, \"parameters\": {\"global_step\": \"global_step:0\"}, \"outputs\": {\"categorical_logits\": \"add:0\"}}\n"
     ]
    }
   ],
   "source": [
    "filename = simple_model(28, 28, 3, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1479433139451_2\n",
      "Status of Deep Learning Model: user, 41.7 KB, predicting C2, 3-class classification, 134,144 training samples, mini-batch size 32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2352</td>\n",
       "<td>0.0044086</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate        momentum\n",
       "--  ---------------  ----------  ----------\n",
       "    2352             0.00440861  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 6.60075876885e+12\n",
      "RMSE: 2569194.18668\n",
      "LogLoss: -14.4921790248\n",
      "Mean Per-Class Error: 0.0\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>cat</b></td>\n",
       "<td><b>dog</b></td>\n",
       "<td><b>mouse</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>90.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 90</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>85.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 85</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 92</td></tr>\n",
       "<tr><td>90.0</td>\n",
       "<td>85.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 267</td></tr></table></div>"
      ],
      "text/plain": [
       "cat    dog    mouse    Error    Rate\n",
       "-----  -----  -------  -------  -------\n",
       "90     0      0        0        0 / 90\n",
       "0      85     0        0        0 / 85\n",
       "0      0      92       0        0 / 92\n",
       "90     85     92       0        0 / 267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    1\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:44:13</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:44:15</td>\n",
       "<td> 1.936 sec</td>\n",
       "<td>575 obs/sec</td>\n",
       "<td>3.8352060</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>1327446.7778600</td>\n",
       "<td>nan</td>\n",
       "<td>0.5655431</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:44:20</td>\n",
       "<td> 7.009 sec</td>\n",
       "<td>7934 obs/sec</td>\n",
       "<td>203.2659176</td>\n",
       "<td>53</td>\n",
       "<td>54272.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:44:25</td>\n",
       "<td>12.155 sec</td>\n",
       "<td>8733 obs/sec</td>\n",
       "<td>391.1910112</td>\n",
       "<td>102</td>\n",
       "<td>104448.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-17 17:44:30</td>\n",
       "<td>16.732 sec</td>\n",
       "<td>8118 obs/sec</td>\n",
       "<td>502.4119850</td>\n",
       "<td>131</td>\n",
       "<td>134144.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-11-17 17:44:13  0.000 sec                     0         0             0          nan              nan                 nan\n",
       "    2016-11-17 17:44:15  1.936 sec   575 obs/sec       3.83521   1             1024       1.32745e+06      nan                 0.565543\n",
       "    2016-11-17 17:44:20  7.009 sec   7934 obs/sec      203.266   53            54272      2.56919e+06      -14.4922            0\n",
       "    2016-11-17 17:44:25  12.155 sec  8733 obs/sec      391.191   102           104448     2.56919e+06      -14.4922            0\n",
       "    2016-11-17 17:44:30  16.732 sec  8118 obs/sec      502.412   131           134144     2.56919e+06      -14.4922            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = H2ODeepWaterEstimator(epochs=500, \n",
    "                              network_definition_file=filename,  ## specify the model\n",
    "                              image_shape=[28,28],  ## provide expected (or matching) image size\n",
    "                              channels=3,\n",
    "                              backend=\"tensorflow\", \n",
    "                             ) \n",
    "model.train(x=[0], y=1, training_frame=frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
